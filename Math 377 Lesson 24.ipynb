{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 24: Hypothesis Testing Errors & Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr. Warner Notes:\n",
    "\n",
    "Court: Not guilty = fail to reject\n",
    "\n",
    "type 1: null is true, but you reject it. Send an innocent person to the big house.\n",
    "probability of type 1 is alpha (5%), or beyond a reasonable doubt\n",
    "\n",
    "type2: null is false, but you fail to reject it. OJ Simpson.\n",
    "\n",
    "\n",
    "power is 1 minus the probability of type 2. you want to make power high, because it is the probability that we reject the nulle when the alternative is true\n",
    "\n",
    "Making a type 1 error less likely makes a type 2 error more likely. It is a zero sum game.\n",
    "\n",
    "Shift tab brings up documentation for commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this block, we have been studying hypothesis tests. We have covered the four basic steps of any hypothesis test, and we have practiced various methods for obtaining the distribution of our test statistic under the null hypothesis. \n",
    "\n",
    "After we have reached a conclusion (reject or fail to reject), we must consider possible errors. \n",
    "\n",
    "### Type I error \n",
    "\n",
    "Type I error is the event that we rejected the null hypothesis when the null hypothesis was actually true. Type I error is also known as a false positive. The probability of a Type I error is usually defined by the threshold used for rejection. A common threshold is 0.05. Those of you who have taken statistics before may recognize this value as $\\alpha$. \n",
    "\n",
    "### Type II error\n",
    "\n",
    "Type II error is the event that we failed to reject the null hypothesis when the null hypothesis was actually false. This is otherwise known as a false negative. The probability of a Type II error is harder to find and requires a more in-depth analysis of a hypothesis test. The probability of a Type II error is often given as $\\beta$, and $1-\\beta$ is referred to as **Power**. The power of a test is probability that we will reject the null hypothesis when we are supposed to. \n",
    "\n",
    "Which one of these errors is more serious? It depends on the context of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Golf Balls\n",
    "\n",
    "Joe has a summer job at a golf course and one of his jobs is to fish out golf balls from the water traps. He has a theory that certain types of golf ball are more likely to end up in the water than others. Let's assume there are four brands of golf ball, let's and assume that all four are used equally at this golf course. He fishes out 100 golf balls and counts each brand. He finds 30 of brand A, 30 of brand B, 20 of brand C and 20 of brand D. Conduct a hypothesis test to determine whether certain types of golf ball are more likely than others to end up in the water."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Hypotheses\n",
    "\n",
    "Null: All brands are equally likely to end up in the pond.(We find 25 of each)\n",
    "\n",
    "Alternative: Some of the brands are found more than others. At least one is different from the rest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Test statistic\n",
    "\n",
    "There are many correct answers, but let's go with sum of absolute difference between observed and expected counts under $H_0$. To do this, we need to find the expected counts. If each ball was equally likely, how many should we expected to find of each if we select 100 golf balls? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: $p$-value\n",
    "\n",
    "We need the distribution of the test statistic under $H_0$. \n",
    "\n",
    "The sum of the difference is 2(30-25)+2(25-20) = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  8.,  8., ..., 14., 16., 12.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is how you set up a simulation. This is not a binomial, so I went with the simulation method.\n",
    "Brand = ['A','B','C','D']\n",
    "T = []\n",
    "\n",
    "for n in np.arange(10000):\n",
    "    X = np.random.choice(Brand,100,replace=True)\n",
    "    T = np.append(T,abs(sum(X == 'A')-25) + abs(sum(X == 'B')-25) + abs(sum(X == 'C')-25) + abs(sum(X == 'D')-25))\n",
    "    \n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clean up the coding at by looking at his functions. Note: stats.multinomial is like the binomial, but with 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1879"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the problem is to determine what the probability is. It probably should not be that it is exactly 20, but\n",
    "#that it is 20 or greater, because it is my data or more extreme in all cases.\n",
    "#The abs difference has turned a two-sided problem into a one-sided one\n",
    "\n",
    "p = sum(T>19)/10000\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Conclude\n",
    "\n",
    "We fail to reject because it is too likely that we get the data we have if we expect all balls equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of error could we have made in this case? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We failed to reject, so we could have made a Type 2 error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power \n",
    "Suppose that, in truth, 30% of the balls found in the water were brand A, 30% were brand B, 20% were brand C and 20% were brand D. In this case, our collected sample reflected this truth perfectly. However, our hypothesis test failed to recognize this deviation from equal proportions. We made a type II error. This is because this test has fairly low power. Use simulation to determine the power of this test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr. Warner in class notes:\n",
    "\n",
    "He gave us the actual distribution given the alternative is true. stats.multinomial(n=100,[.3,.3,.2,.2])\n",
    "When power comes out too low and we fail to reject, we simply need more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am looking for the probability that I reject the null hypothesis given the true proportions laid out above. Well, first I need to figure out for what values of my test statistic I would reject $H_0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0421\n",
      "All values greater than or equal to 25 would cause us to reject the null\n"
     ]
    }
   ],
   "source": [
    "# Just pull down the T data from above.\n",
    "def P_val(X):\n",
    "    return sum(T>=X)/len(T)\n",
    "\n",
    "print (P_val(25))\n",
    "#play around with the value until you get the first output less than 0.1\n",
    "print('All values greater than or equal to 25 would cause us to reject the null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need to simulate from the true population and determine how often my test statistic would have met this threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true_pop = stats.multinomial(100,[.3, .3, .2, .2]) I am not sure how this works\n",
    "\n",
    "#Here I will try to simulate again, this time drawing from a pool of 30 A, 30 B, 20 C 20 D\n",
    "\n",
    "Weighted_Brand = np.repeat('A',30)\n",
    "Weighted_Brand = np.append(Weighted_Brand,np.repeat('B',30))\n",
    "Weighted_Brand = np.append(Weighted_Brand,np.repeat('C',20))\n",
    "Weighted_Brand = np.append(Weighted_Brand,np.repeat('D',20))\n",
    "stat = []\n",
    "for n in np.arange(10000):\n",
    "    dist = np.random.choice(Weighted_Brand,100)\n",
    "    stat = np.append(stat,abs(sum(dist == 'A')-25) + abs(sum(dist == 'B')-25) + abs(sum(dist == 'C')-25) + abs(sum(dist == 'D')-25))\n",
    "\n",
    "sum(stat>=25)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta$ is the probability of a type 2 error, that we would fail to reject even though the null is not true. $\\beta$ is the conjugate of power. Above, we found the power, the probability that we would reject given that null was false (here described by the given distribution). Our power=34.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think about this power? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This power is low. Given a random sample from this distribution, we would fail to reject the null more than half the time, even though the null is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this power calculation, but assume Joe collects 500 balls instead of 100. Note that you will have to obtain a new critical value. What does this tell you about power and sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will give us the new value assuming the null is true with a sample size of 500, find the p value\n",
    "#Note, Brand is the same as last time, equal probability, simulation:\n",
    "statistic = []\n",
    "for n in np.arange(10000):\n",
    "    X = np.random.choice(Brand,500)\n",
    "    statistic = np.append(statistic,abs(sum(X == 'A')-125) + abs(sum(X == 'B')-125) + abs(sum(X == 'C')-125) + abs(sum(X == 'D')-125))\n",
    "    \n",
    "# Just for curiosity's sake, what is the probability that we would have the same distribution given that the null was true:\n",
    "#Note, the differences would be 150-125 and 125-120, resulting in an expected test statistic of 100.\n",
    "sum(statistic>=100)/10000\n",
    "#This came out at practically 0 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0441\n",
      "55 is the new cutoff for our test statistic where we would reject the null\n"
     ]
    }
   ],
   "source": [
    "#Find the new cutoff\n",
    "print(sum(statistic>=55)/10000)\n",
    "print('55 is the new cutoff for our test statistic where we would reject the null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming a 30-30-20-20, what is the probability we would reject?\n",
    "Weighted_Brand = np.repeat('A',150)\n",
    "Weighted_Brand = np.append(Weighted_Brand,np.repeat('B',150))\n",
    "Weighted_Brand = np.append(Weighted_Brand,np.repeat('C',100))\n",
    "Weighted_Brand = np.append(Weighted_Brand,np.repeat('D',100))\n",
    "stat = []\n",
    "for n in np.arange(10000):\n",
    "    dist = np.random.choice(Weighted_Brand,500)\n",
    "    stat = np.append(stat,abs(sum(dist == 'A')-125) + abs(sum(dist == 'B')-125) + abs(sum(dist == 'C')-125) + abs(sum(dist == 'D')-125))\n",
    "\n",
    "Power = sum(stat>=55)/10000\n",
    "Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our power has increased to near 100%. A type 2 error would be extremely unlikely given a sample size of 500 and a 30-30-20-20 distribution. The more data that is in a sample, the less likely we are to make mistakes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
